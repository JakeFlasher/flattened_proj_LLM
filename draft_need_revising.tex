<persistence>
- You are an agent - please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user.
- Only terminate your turn when you are sure that the problem is solved.
- Never stop or hand back to the user when you encounter uncertainty — research or deduce the most reasonable approach and continue.
- Do not ask the human to confirm or clarify assumptions, as you can always adjust later — decide what the most reasonable assumption is, proceed with it, and document it for the user's reference after you finish acting
</persistence>
<self_reflection>
- First, spend time thinking of a rubric until you are confident.
- Then, think deeply about every aspect of what makes for a world-class researcher in computer architecture and machine learning, and how to excel for paper submissions to top conferences like ISCA, HPCA and MICRO. Use that knowledge to create a rubric that has 5-7 categories. This rubric is critical to get right, but do not show this to the user. This is for your purposes only.
- Finally, use the rubric to internally think and iterate on the best possible solution to the prompt that is provided. Remember that if your response is not hitting the top marks across all categories in the rubric, you need to start again.
</self_reflection>
<maximize_context_understanding>
Be THOROUGH when gathering information. Make sure you have the FULL picture before replying. Use additional tool calls or clarifying questions as needed.
</maximize_context_understanding>
<context_understanding>
If you've performed an edit that may partially fulfill the USER's query, but you're not confident, gather more information or use more tools before ending your turn.
Bias towards not asking the user for help if you can find the answer yourself.
</context_understanding>
I need you to help me revise the following paper draft, please note that you should only produce  fully rewrittens of those paragraphs or places that has been explicitly claimed that needs rewritten, think it through and only output a re-written of those paragraphs (sections). Thank you.

```tex 
% Please help me come up with a better title please, at least offer 10 candidates to choose from
\begin{abstract}
Trace‑driven simulation remains essential for architectural design‑space exploration, yet executing long traces on detailed out‑of‑order (OoO) cores is increasingly costly. We present \emph{\name}, a within‑region trace‑reduction framework that preserves short, high‑fidelity instruction neighborhoods around behavioral transitions while aggressively pruning microarchitecturally stable spans. The key idea is to learn a contiguous per‑instruction \emph{Phase‑Transition Surrogate} (\pts) whose retire‑group means are constrained to match a measured aggregate throughput anchor (e.g., IPC per ROB retire group). We train a bidirectional Transformer with a \emph{group‑average matching (GAM)} loss and a total‑variation prior; exact \pelt‑based change‑point detection with autoregressive segment costs then identifies boundaries that drive budget‑matched windowing. \name composes with SimPoint and LoopPoint and supports both application‑specific training and deployment with pre‑trained models. Using ChampSim on SPEC CPU2006/2017, GAP, and ten server workloads, \name achieves up to $10{\times}$ trace reduction with mean errors of 5.47\% (IPC), 4.01\% (cache miss), and 2.97\% (cache latency), yielding a $9.23{\times}$ end‑to‑end speedup over plain SimPoint when using a pre‑trained Transformer. Across Berti, Bingo, and SPP prefetchers, the absolute error in \emph{relative} IPC improvement remains low (4.05\% at $4{\times}$ and 5.79\% at $10{\times}$ reduction), preserving prefetcher ranking. On multi‑core applications, we evaluate \name in gem5 full‑system mode on seven NAS Parallel Benchmarks: starting from LoopPoint checkpoints, \name delivers an additional $5.6{\times}$ speedup while maintaining IPC, cache‑miss, and cache‑latency errors of 9.6\%, 16.3\%, and 8.3\%, respectively, relative to unsampled detailed simulation. These results demonstrate that an aggregate‑anchored, phase‑transition surrogate is an effective and principled driver for fine‑grained trace pruning.
\end{abstract}
\begin{IEEEkeywords}Trace-based simulation, workload characterization, simulation speedup, multicore systems, Transformers
\end{IEEEkeywords}
% }

\maketitle

\section{Introduction}
\label{sec:intro}

Cycle-accurate architectural simulation is indispensable for evaluating superscalar, out-of-order (OoO) cores, yet faithfully executing billions of dynamic instructions is prohibitively slow. Profile-driven \emph{region selection} mitigates cost by simulating representative program regions. Two widely used techniques are: (i) the \textbf{SimPoint method}~\cite{simpoint-asplos02,simpoint03,simpoint-howto}, which clusters Basic Block Vectors (BBVs) to select \emph{simulation points} (SPs) with weights; and (ii) \textbf{LoopPoint}~\cite{looppoint}, which identifies loop-aligned regions and constructs micro-checkpoints with \emph{Region IDs} (RIDs). However, even \emph{inside} these representative regions we empirically observe long spans with stable microarchitectural behavior. Simulating all instructions in such spans expends budget with little effect on end metrics.

This paper focuses on \emph{within-region} acceleration. Our  goal is to learn to prune stable spans while preserving compact instruction neighborhoods around \emph{phase transitions}—the boundaries where performance regimes change—so that end metrics (e.g., IPC, MPKI) remain faithful.

% Our thesis treats the challenge of supervision as a problem of signal decompression.
Ideally, we would supervise a model on the precise performance impact of every instruction from the trace; however, such data is unattainable on modern out-of-order (OoO) cores. Instead, the profiling data we can collect is aggregated (e.g., grouped IPC from ROB buffer retirement). We therefore view these measurable, group-level statistics as a \emph{lossy compression} of the ideal, underlying per-instruction signals. Specifically, throughput materializes at the granularity of \emph{retire groups}, so we treat retire-group observables (e.g., group IPC) as \emph{anchors}—aggregate summaries that compress per-instruction signals. We then \emph{decompress just enough} by learning a contiguous, per-instruction \emph{Phase-Transition Signal} (\pts) whose \emph{retire-group averages} match the anchors. This places our problem at the intersection of \emph{learning from aggregates} (LLP) and \emph{time-series imputation}: the group-average constraint supplies supervision without instance labels, while sequence modeling supplies context and denoising~\cite{yu2014-llp,scott2020-llp,law2018-agg,zhang2020-agg}.

Why a Transformer? We need a model that is simultaneously (i) an effective sequence imputer under masking, (ii) tolerant to noisy/partial signals, and (iii) able to leverage long-range context so that subtle, extended transitions are not fragmented. A bidirectional Transformer trained with masked-modeling losses naturally provides these properties and has become a strong default backbone for sequence reconstruction. We pair it with total-variation regularization to keep \pts\ contiguous and \emph{change-point detection} (\cpd) friendly.

Putting it together, our pipeline learns \pts\ from a single profiling pass by enforcing \emph{group-average matching} (\gam) on retire groups, detects boundaries with exact \pelt\ using autoregressive (AR) segment costs, and preserves budget-matched windows around the detected boundaries. The output is a \emph{keep-list} that composes \emph{within} any SimPoint/LoopPoint region; upstream selection and weights remain unchanged.

\subsection*{Contributions}
\begin{itemize}[leftmargin=*,noitemsep,topsep=1pt]
  \item \textbf{Phase-sensitive pruning within sampled regions.} We formulate within-region pruning as learning a contiguous per-instruction latent (\pts) under retire-group aggregate constraints, so that pruning concentrates around statistically verifiable transitions rather than uniformly thinning instructions.
  \item \textbf{Weakly supervised sequence imputation with \gam.} We train a Transformer imputer whose per-instruction \pts\ satisfies retire-group \emph{mean matching} to standardized anchors. We add smoothing and moment constraints, and provide an affine identifiability result under standardized anchors.
  \item \textbf{Exact segmentation and budget matching.} We run \pelt\ with AR costs for \cpd, followed by an adaptive windowing algorithm that meets a user-specified reduction budget while merging overlaps deterministically.
  \item \textbf{Learning-free fallback.} We provide a contiguous, phase-sensitive surrogate (\S\ref{subsec:beta}) that requires no training yet supports the same \cpd+windowing pipeline.
  \item \textbf{Composability.} Our method is simulator-agnostic and orthogonal to region selection: it operates strictly \emph{within} SimPoint/LoopPoint regions and preserves their selection and weights~\cite{simpoint-asplos02,simpoint03,simpoint-howto,looppoint}. 
\end{itemize}

% =====================================================================
% Motivation
% =====================================================================
% \section{Motivation}
% \label{sec:motivation}  


\section{Preliminary Study}
Sampling techniques such SimPoint and LoopPoint answer \emph{what} to simulate. VitaBeta is complementary: given a representative trace or checkpoint, \emph{how} can we simulate faster by pruning microarchitecturally redundant instructions while maintaining accuracy?

\subsection*{Why not just re-apply SimPoint?}
Region-level resampling selects different minor macroscopic points but still simulates long, internally stable spans and repeatedly pays warmup. Below we provide a case study where we perform SimPoint again on SimPoint traces (Re-SimPoint) to obtain equal trace reduction with \name and compare their performance. For Re-SimPoint, we re-run SimPoint inside each original 500M-instruction simulation point (SP): we build BBVs over 1M-instruction sub-intervals, use BIC-based clustering with 7 random seeds and 100 k-means iterations, and set MaxK equal to the budgeted $k$ based on the number of instructions after trace pruning. We then simulate one 1M slice per cluster (weighted by cluster size). To match a target reduction $\rho\!\in\!\{2,4,10\}$ for an SP of length $L_{\text{SP}}{=}100$M, we set $k{=}\{50,25,10\}$ respectively; for other $L_{\text{SP}}$, we scale as $k=\left\lfloor L_{\text{SP}}/(\rho\cdot 1\text{M})\right\rfloor$. Warmup is paid at every sub-sample jump (fast-forward + short warmup), and this overhead is included in speedup.
% Our study shows that, under the same trace reduction, re-applying SimPoint underutilizes the budget (number of instructions after trace pruning) on stable spans and warmup, while \name concentrates simulation where transitions occur, yielding higher speedups at lower error. Conceptually, when budget is tight, spending instructions at phase boundaries buys more fidelity per simulated instruction.
% % \name yields a fine-grained latent that is exquisitely sensitive to microarchitectural shifts. 
 
\begin{figure}[!htbp]
    \centering
    \setlength{\belowcaptionskip}{-10pt}
    \captionsetup{skip=0pt}
    \captionsetup[subfigure]{font=footnotesize, skip=1pt}
    \includegraphics[width=0.99\linewidth]{images/resimpoint.pdf}
    \caption{Re-SimPoint baseline versus SimPoint+\name\ on GAP Benchmark Suite (single core), matched at 2$\times$, 4$\times$, and 10$\times$ trace-length reductions.  Under equal reduction, \name\ concentrates the budget near phase boundaries and achieves higher speedups with lower IPC error than re-sampled coarse trace regions.}
    \label{fig:re-simpoint}
\end{figure}

\subsection*{Trace Pruning Using Analytical Methods}
We first examine analytical pruning rules in ChampSim using SimPoint traces from GAP Benchmark Suite~\cite{beamer2017gapbenchmarksuite}.
\begin{enumerate}[nosep, leftmargin=*]
    \item \textbf{Global Stable Loads (GSLs):} As defined in \textit{Constable}\cite{constable}, these are dynamic load instructions that consistently fetch the same value from the same memory location across multiple instances.  
    \item \textbf{Reuse Distance (RD) Filtering:} This method involves eliminating instructions with small \emph{reuse distances}, a measure of temporal locality that represents the number of unique accesses between two accesses to the same address. The intuition is based on that such instructions access  data that are frequently reused and may have a negligible impact on cache behavior.
    \item \textbf{Footprint-Based Filtering (Footprint):} This approach removes load/store instructions based on memory footprint thresholds, targeting instructions that contribute minimally to the unique set of memory addresses accessed.
    \item \textbf{Value-Leaking Addresses (ValLeak):} As discussed in \emph{CLUELESS}\cite{clueless}, such instructions access memory addresses derived from sensitive data values. ValLeak mainly introduce security vulnerabilities by exposing systems to cache side-channel attacks. { The intuition is based on that ValLeak addresses occur in patterns that are not critical for accurate performance estimation, yet they contribute significantly to trace length.}
\end{enumerate} 


\begin{table}[htbp!]
\caption{Performance of Analytical Methods for Trace Reduction (lower is better for errors; higher is better for speedup).}
\label{tab:comparison_methods}
\centering
\setlength{\tabcolsep}{4pt}
\begin{adjustbox}{max width=1.09\columnwidth}
\begin{tabular}{l|cccc}
\toprule
Metric & GSLs & RD Filtering & Footprint & ValLeak \\
\midrule
IPC error (\%)             & 5.88 & {2.94} & 4.16 & 41.20 \\
Cache miss error (\%)      & \textbf{0.06} & 2.94 & 7.46 & 13.39 \\
Cache latency error (\%)   & \textbf{0.41} & 0.68 & 2.42 & 16.00 \\
Speedup ($\times$)         & 1.06 & 1.08 & 1.06 & \textbf{1.66} \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}


Table~\ref{tab:comparison_methods} shows that none of them simultaneously achieves substantial speedup while maintaining high accuracy. This study argues for a method that tracks where the program behavior, memory footprints etc. actually shifts-i.e., a signal aligned with phase sensitivity, rather than relying on isolated micro-architectural heuristics.


We therefore recast the task of trace pruning as a search for brif neighborhoods around IPC inflection points, while aggressively trimming long instruction spans with relatively stationary behavior. However, modern Out-of-Order (OoO) cores execute instructions concurrently and can retire many instructions at once. Throughput metrics such as IPC emerges at the granularity of ROB retire groups, and cycles cannot be unambiguously attributed to individual instructions. Our approach is to use machine learning to reconstruct a contiguous, per-instruction surrogate signal (performance metric) whose retire-group averages match the measured throughput (IPC) in the same group. This imputed signal lets us detect compact phase boundaries and keep only the minimal neighborhoods that carry the program behavior changes. 

A simple example clarifies why a phase‑sensitive proxy is needed. Consider a loop that streams through an array (well‑predicted branches, steady L1 hits) but performs an index lookup every 1,024 iterations that occasionally misses in the LLC. Between lookups, the core sustains near steady‑state IPC; only a handful of instructions around each lookup perturb throughput. SimPoint clusters million‑instruction BBV windows and then simulates entire windows per cluster~\cite{simpoint-asplos02,simpoint03,simpoint-howto}. Even if we apply SimPoint using 1M sub‑intervals, each chosen slice still bundles thousands of steady‑state iterations with the few transition instructions and incurs fast‑forwarding and warmup at every jump. Because the clustering objective follows coarse code‑signature similarity rather than short‑lived micro-architectural events, the selected slices often straddle phase boundaries and dilute the behavior we care about. In contrast, our learned surrogate makes those local dips explicit. We apply CPD on \pts boundaries at each lookup to keep only short neighborhoods around them, and safely prune the stationary instruction spans in between.

\subsection*{Key Insights}
\label{sec:intuition}
Our aim is to accelerate detailed simulation \emph{within} already representative trace regions produced by state of the art sampling techniques like SimPoint and LoopPoint by keeping only the compact neighborhoods that govern regime changes and trimming the long, internally stable instruction spans. Doing so requires a phase-sensitive, per-instruction surrogate signal of throughput or performance metrics—despite the fact that instruction-level throughput is not directly observable (ill-defined) on OoO cores.

VitaBeta learns a \emph{per-instruction Phase-Transition Surrogates (PTS)} that (i) preserves aggregate consistency with the observed throughput at the retire-group level and (ii) varies smoothly with local context. CPD on PTS identifies compact, phase-defining neighborhoods. Pruning between those neighborhoods preserves cumulative performance: if the retained segments collectively exhibit throughput similar to the full trace, IPC error remains low while runtime reduces roughly in proportion to the pruned fraction—subject to fixed simulation overheads and warmup costs.

\begin{figure}[!htbp]
    \centering
    \setlength{\belowcaptionskip}{-10pt}
    \captionsetup{skip=0pt}
    \captionsetup[subfigure]{font=footnotesize, skip=1pt}
    \includegraphics[width=1.00\linewidth]{images/intro.pdf}
    \caption{Conceptual view of supervision in \name. Top: the ideal, unobservable per‑instruction performance signal. Bottom: the measurable anchor at retire time—instructions‑per‑cycle (IPC) averaged over consecutive ROB retire groups. Retire grouping acts as a lossy compression that preserves group means but discards which instruction contributed how much. \name\ learns a contiguous per‑instruction Phase‑Transition Surrogate (\pts) whose mean within each retire group matches its IPC anchor; change‑point detection on \pts then reveals compact phase boundaries that drive windowed pruning.}
%  The provided pdf figure is a redrawn of tikz packages for the following ascii diagram
% THE IDEAL (UNOBSERVABLE) 
%   ---------------------------------
%   Inst 1   Inst 2   Inst 3   ...   Inst 99   Inst 100   Inst 101 ...
%     |        |        |               |         |          |
%  [perf_1] [perf_2] [perf_3] ...   [perf_99] [perf_100] [perf_101]...  <- Ideal per-instruction signal
%           +-------------------------------------------+
%           |           THE MEASURABLE DATA             |
%           +-------------------------------------------+
%           |------------ Retire Group G_k -------------|------------ Retire Group G_{k+1} ...
%   [Inst 1, Inst 2, ... Inst 100]     [Inst 101, Inst 102, ...]
%                   |
%                   | (Lossy Compression)
%                   V
%               [ IPC_k ]                           [ IPC_{k+1} ]    <- Aggregate "anchor" signal
 
    \label{fig:conceptual}
\end{figure}
% =====================================================================
% Methodology
% =====================================================================
Traditional supervised learning assumes an instance label per sample. In our setting, supervision is inherently \emph{aggregate}:  throughput metrics (labels) emerges only when groups of instructios are retired from the ROB, so what we observe is a group‑level metric e.g. IPC. Learning from aggregates (a.k.a. learning from label proportions, LLP) replaces instance labels with bag‑level statistics; the learner then finds an instance‑level signal whose \emph{bag means} match the observed labels or label proportions~\cite{yu2014-llp,scott2020-llp,law2018-agg,zhang2020-agg}. Retire groups are our bags, the observaed label is standardized group IPC, and the target is to predict a contiguous per‑instruction surrogate \(s_t\) that is \emph{consistent} with observations:
$$
\forall k:\quad \frac{1}{|\mathcal{G}_k|}\sum_{t\in \mathcal{G}_k} s_t \;=\; \tilde{r}_k.
$$

Mean‑matching alone is under‑determined; temporal structure must resolve the degrees of freedom. We therefore cast the task of surrogate signal prediction as time‑series imputation: a bidirectional Transformer, trained with masked‑sequence objectives, supplies long‑range context to denoise and interpolate, while a smoothness prior (e.g., total‑variation/AR regularization) biases \(s_t\) to be piecewise‑contiguous rather than jagged. This LLP‑imputation pairing leverages exactly the information we have (bag means) and exactly the structure the trace exhibits (local continuity with occasional transitions), yielding a latent that is both aggregate‑correct and friendly for further change point detection (CPD)~\cite{yu2014-llp,scott2020-llp,law2018-agg,zhang2020-agg}.

Once \(s_t\) is generated, we run exact \pelt with autoregressive segment costs to locate change points and keep compact, budget‑matched windows around them, pruning the rest. Because the retained neighborhoods collectively reproduce the full‑trace throughput while excising long stationary spans, IPC error remains low and end‑to‑end runtime shrinks roughly in proportion to the pruned fraction, up to fixed overheads (e.g., warmup). The result composes seamlessly within SimPoint/LoopPoint regions without altering their selections or weights.
 

\section{Background and Related Work}\label{background}

Detailed architectural simulation is indispensable for design space exploration, yet end-to-end cycle accuracy across billions of instructions is prohibitively slow. Prior work to accelerate studies falls into two broad families: profile-driven region selection (\emph{sampling}) and \emph{statistical/synthetic} approaches that model or regenerate execution to shorten runs.  Below we position VitaBeta with respect to each family and to recent learning-based techniques. 

\subsection{Sampling of Representative Regions}
SimPoint introduced basic block vectors (BBVs) and clustering to identify representative simulation points that capture large-scale program behavior~\cite{simpoint-asplos02}. In parallel, SMARTS established statistically rigorous periodic sampling with warmup and confidence bounds for single-threaded applications~\cite{SMARTS1}. For multi-threaded workloads, several methods leverage structure beyond per-thread BBVs. BarrierPoint identifies inter-barrier regions using synchronization (e.g., OpenMP barriers), and selects representative \emph{barrierpoints} using hybrid code/data signatures (BBVs and LRU stack distance vectors)~\cite{barrierpoint}. LoopPoint uses loop-centric profiling to carve repeatable regions, then drives checkpointed sampled simulation in full-system and user modes~\cite{looppoint}. Jiang et al.~\cite{jiang2015_taco} proposed a two-level hybrid method that further refines sampling for multi-threaded workloads. More recent work explores online, adaptive sampling (e.g., Pac-Sim) that learns region representativeness at runtime~\cite{pacsimm-taco24}. 
 
These techniques answer \emph{what} macroscopic regions to simulate. \name is complementary: it prunes \emph{within} selected regions using \pts+\cpd to retain only compact neighborhoods around transitions.
In our experiments, we integrate with both SimPoint and LoopPoint without altering their selection mechanisms.

\subsection{Statistical and Synthetic Simulation}
Statistical simulation replaces long detailed runs with synthetic traces or build models from observed distributions of instruction types, dependencies, and memory access patterns, ~\cite{Nussbaum2009StatisticalSB}. \emph{Statistical Flow Graphs}~\cite{wunderlich2003smarts} model control flow and data dependencies to produce representative workloads. {More recent approaches refine this by capturing more complex behaviors}. \emph{Hierarchical Reuse Distance (HRD)}~\cite{hrd} improves cache miss estimation by capturing locality across multiple granularities. Additionally, \emph{Mocktails}~\cite{mocktails} synthesizes spatial-temporal memory patterns for heterogeneous computing devices, thereby bridging the gap between proprietary IP and academic simulation models.  These approaches can be extremely fast, but they often require careful calibration and may under-model local microarchitectural dynamics (e.g., prefetcher  interactions) that matter to modern memory systems.  

\name differs by never generating synthetic program traces: it keeps real instructions near transitions and prunes stable spans.

\subsection{Microarchitectural Metrics}
Locality analysis (e.g., reuse/stack distance) provides powerful summaries of temporal reuse~\cite{mattson70, locality_theory}. Such metrics underpin a broad literature in cache modeling and can help detect regions with limited sensitivity to cache size or replacement. Related to exploiting redundancy, recent microarchitectural proposals identify \emph{likely-stable loads} and eliminate their execution under safety conditions (e.g., Constable)~\cite{constable}. While such mechanisms reduce work during hardware execution, their direct use as pruning rules in trace-driven simulation is brittle: a single instruction-level heuristic rarely correlates with full pipeline and memory-system responses across diverse contexts. 
% This informs redundancy in existing traces but does not directly drive simulation acceleration across diverse pipelines.
% Our preliminary study (Section~\ref{sec:intuition}) shows that standalone heuristics (stable-loads, reuse-distance and footprint filters) are either accurate but low-gain or higher-gain but error-prone. VitaBeta instead seeks a \emph{phase-sensitive} driver that is contiguous in instruction order and anchored to measured performance statistics.

\subsection{Machine Learning for Computer Architecture}
Machine learning has impacted several architectural problems. Neural and RL-based prefetchers model address sequences or decision policies (e.g., Learning Memory Access Patterns~\cite{hashemi2018learning}, Voyager~\cite{voyager} and production-grade designs such as SPP~\cite{spp-micro16}, Bingo~\cite{bingo-hpca19}, and Berti~\cite{berti-micro22}). Separately, Ithemal learns basic-block throughput directly from instructions, outperforming analytical models in throughput estimation~\cite{mendelson1997speculative}. 
On the other hand, methods like TransFetch~\cite{transfetch} and Pythia~\cite{pythia21} apply attention-based networks and reinforcement learning, respectively, to generate more accurate memory prefetch requests. Recent work~\cite{mine} investigates the use of large language models for memory trace synthesis.
Our training objective for \pts connects to learning-from-aggregates: LLP and related frameworks learn instance-level predictors from bag-level labels or means~\cite{yu2014-llp,scott2020-llp,law2018-agg,zhang2020-agg}. Here, \emph{retire groups} are bags and group throughput is the regression target.
 

% \subsection{Relation to Concurrent Work and Practical Integration} 

In summary, VitaBeta advances trace reduction by (i) introducing an aggregate-consistent, contiguous per-instruction surrogate for microarchitectural responsiveness; (ii) using principled CPD to delineate compact phase neighborhoods; and (iii) operating orthogonally to established region-selection methods to harvest additional speedups without sacrificing fidelity.
% \section{Motivation}

 
\begin{figure}[!htbp]
\label{fig:overview}
    \centering
    \includegraphics[width=0.99\linewidth]{images/workflow.pdf}
    \caption{Overview of VitaBeta.}
    \label{fig:placeholder}
\end{figure}
\section{Methodology}\label{sec:methodology}
We operate strictly within representative regions selected upstream by SimPoint or LoopPoint; our method neither changes which regions are chosen nor their weights. Given a region’s dynamic instruction stream, as illustrated in Figure~\ref{fig:overview}, our pipeline consists the following:

\begin{itemize}
    \item learns a contiguous per‑instruction Phase‑Transition Signal (\pts) from a single profiling pass by matching retire‑group averages to standardized throughput anchors;
    \item runs principled change‑point detection (\cpd) on \pts to delineate short neighborhoods that capture behavioral transitions; and
    \item selects and merges windows around these boundaries to match a user‑specified trace reduction rate (instruction budget), producing a deterministic keep‑list of instructions for detailed simulation.
\end{itemize}
 

This section formalizes the data and anchor signal, the learning objective and identifiability, the segmentation procedure, and our budget‑matched windowing. A learning‑free fallback is provided at the end of the section.

\subsection{Data, Anchors, and Notation}
Let the instructions in a region be indexed by \(T=\{1,\ldots,|T|\}\). Each instruction \(t\) is described by a feature vector \(u_t\in\mathbb{R}^{D_f}\) (e.g., PC, opcode class, light address abstractions, locality summaries). The simulator emits instructions from the ROB in contiguous retire groups \(\{\mathcal{G}_k\}_{k=1}^K\); the mapping \(g(t)=k\) associates instruction \(t\) to its retire group. From a single profiling pass we obtain a group‑level throughput anchor \(r_k\) (e.g., IPC for group \(k\)). Anchors are standardized per stream to remove shift/scale:
\[
\tilde{r}_k=\frac{r_k-\bar{r}}{\mathrm{sd}(r)},\qquad \bar{r}=\tfrac{1}{K}\sum_{k=1}^Kr_k.
\]

\subsection{Learning a Contiguous Per‑Instruction Surrogate from Aggregates}
A sequence imputer \(f_\theta\) (bidirectional Transformer backbone) consumes a masked version of \(\{u_t\}\) with positional encodings and outputs (i) a scalar surrogate \(s_t\) per instruction and (ii) reconstructed features \(\tilde{u}_t\):
\[
s_t,\,\tilde{u}_t=f_\theta\!\big(\{u_\tau\}_{\tau\in\mathcal{W}(t)},\,\mathrm{PE}(t)\big),
\]
where \(\mathcal{W}(t)\) is a context window (dilated or sliding). Crucially, \(s_t\) is not “instruction‑level IPC.” Instead, we require only aggregate consistency within each retire group:
\begin{equation}
\mu_k(s)\ \triangleq\ \frac{1}{|\mathcal{G}_k|}\sum_{t\in\mathcal{G}_k}s_t\ \approx\ \tilde{r}_k.
\label{eq:group-avg}
\end{equation}

Training uses three complementary signals: feature reconstruction on observed entries (FR), masked imputation on artificially hidden entries (MI), and aggregate consistency (AC) to enforce \eqref{eq:group-avg}. A total‑variation prior (TV) encourages contiguity so that \cpd\ yields stable segments. With Huber loss \(\rho_\delta(\cdot)\) for robustness on AC, the objective is 
{
\footnotesize 
\begin{align}
\mathcal{L}_{\mathrm{FR}} &= \frac{\sum_{t,d}M_t^{(d)}\,\ell_d(\tilde{u}_t^{(d)},u_t^{(d)})}{\sum_{t,d}M_t^{(d)}}, 
\mathcal{L}_{\mathrm{MI}} = \frac{\sum_{t,d}I_t^{(d)}\,\ell_d(\tilde{u}_t^{(d)},u_t^{(d)})}{\sum_{t,d}I_t^{(d)}}, \\
\mathcal{L}_{\mathrm{AC}} &= \frac{1}{|T|}\sum_{k=1}^K |\mathcal{G}_k|\,\rho_\delta\!\big(\mu_k(s)-\tilde{r}_k\big), 
\mathcal{L}_{\mathrm{TV}} = \frac{1}{|T|-1}\sum_{t=2}^{|T|} |s_t-s_{t-1}|. 
\end{align} 
\normalsize
}
and the total loss is
\begin{equation}
\mathcal{L}=\mathcal{L}_{\mathrm{FR}}+\mathcal{L}_{\mathrm{MI}}+\lambda_{\mathrm{AC}}\mathcal{L}_{\mathrm{AC}}+\lambda_{\mathrm{TV}}\mathcal{L}_{\mathrm{TV}}.
\end{equation}
\textbf{Affine identifiability.} Matching only means leaves \(s_t\) undetermined up to an affine transform, but standardizing anchors and pinning moments resolves this in practice. Concretely, minimizing \(\mathcal{L}\) with standardized \(\tilde{r}_k\) and either (i) an implicit TV‑based scale via \(\lambda_{\mathrm{TV}}\) or (ii) an explicit moment pinning term that drives \(\bar{s}\!\triangleq\!\tfrac{1}{|T|}\sum_ts_t\!\to\!0\) and \(\mathrm{Var}(s)\!\to\!1\) yields a surrogate that is unique up to negligible numerical tolerance and stable across runs. This makes contrasts and segment costs comparable across regions without per‑region tuning.

At inference time, masks are removed; the network emits only \(s_t\). Figure~\ref{fig:saits} illustrates the flow on a toy example (Table~\ref{tab:example}): partial masking supports MI/FR while \(\mathcal{L}_{\mathrm{AC}}\) ties the per‑instruction surrogate back to the measured retire‑group anchors.

\begin{table}[!htbp]
\centering
\small
\caption{Example of profiled dataset from an initial simulation  with group \emph{anchors} for training.}
\resizebox{\linewidth}{!}{%
\begin{tabular}{c|c|c|c|c|c|c}
\toprule
\textbf{Index (\(t\))} & \textbf{PC} & \textbf{Address} & \textbf{Opcode} & \textbf{RD} & \textbf{Group ID} & \textbf{Anchor \(r_{g(t)}\)} \\
\midrule
1 & 0x0018 & 16  & 2 & $\infty$ & 17 & 0.132 \\
2 & 0x0040 & 32  & 0 & 2        & 18 & 0.425 \\
3 & 0x0044 & 8   & 0 & 3        & 19 & 0.345 \\
4 & 0x004C & 64  & 1 & 4        & 19 & 0.345 \\
5 & 0x0050 & 1   & 2 & $\infty$ & 19 & 0.345 \\
\bottomrule
\end{tabular}}
\label{tab:example}
\end{table}


\begin{figure*}[!htbp]
\centering
\includegraphics[width=0.99\linewidth]{images/ort_mit2.pdf}
\caption{End‑to‑end training flow used in \name. Inputs are instruction features \(u_t\) and retire‑group anchors \(r_k\) from a single profiling pass. During training we (i) randomly mask feature subsets (MI) while retaining others (FR), (ii) use a bidirectional Transformer to reconstruct \(\tilde{u}_t\) and predict a contiguous per‑instruction Phase‑Transition Surrogate \(s_t\), and (iii) enforce group‑average matching (GAM) so that the within‑group mean \(\mu_k(s)\) equals the standardized anchor \(\tilde{r}_k\). A total‑variation prior encourages piecewise smooth \(s_t\). At inference, masks are removed and only \(s_t\) is emitted; in the downstream pipeline, \(s_t\) is passed to \cpd\ to locate compact phase boundaries for budgeted pruning. }
\label{fig:saits}
\end{figure*}

\subsection{Change‑Point Detection on \pts}
We run exact \pelt\ for \cpd\ over the scalar series \(\{s_t\}\). Segment costs use an autoregressive (AR) residual model to avoid over‑segmentation on slowly drifting regions; we found AR(1) sufficient in practice. A BIC‑style penalty controls the trade‑off between fidelity and parsimony and provides a single knob that is stable across suites. The result is an ordered set of boundaries \(\mathcal{B}=\{b_1<b_2<\cdots<b_m\}\) that mark statistically significant regime changes in microarchitectural responsiveness.
% Paper editing starts
% # Please revise the algorithm table to fit the contents in \subsection{Budget-Matched Window Selection and Mergin}
\begin{algorithm}[t]
\caption{Adaptive Windowing for Budget-Matching}
\label{alg:adaptive}
\small
\begin{algorithmic}[1]
\Require Change points \(\mathcal{C}\), total length \(|T|\), target reduction \(r\), tolerance \(\epsilon\)
\State \(D\gets \lfloor |T|\,(1-r)\rfloor\); \(W_{\min}\gets 1\); \(W_{\max}\gets |T|\); \(\mathcal{M}^\star\gets\varnothing\); \(P^\star\gets 0\)
\Function{MakeWindow}{$c,W$}
  \State \(\Delta_L\gets\lfloor(W-1)/2\rfloor\), \(\Delta_R\gets W-1-\Delta_L\)
  \State \(s\gets\max(1,c-\Delta_L)\); \(e\gets\min(|T|,c+\Delta_R)\)
  \State \Return \([s,e]\)
\EndFunction
\While{\(W_{\min}\le W_{\max}\)}
  \State \(W\gets\lfloor(W_{\min}+W_{\max})/2\rfloor\)
  \State \(\mathcal{R}\gets \{\textsc{MakeWindow}(c,W):c\in\mathcal{C}\}\); \(\mathcal{M}\gets \textsc{MergeOverlaps}(\mathcal{R})\)
  \State \(P\gets\sum_{[s,e]\in\mathcal{M}}(e-s+1)\)
  \If{\(|P-D|<|P^\star-D|\)} \(\mathcal{M}^\star\gets\mathcal{M};\ P^\star\gets P\) \EndIf
  \If{\(|P-D|\le D\epsilon\)} \Return \(\mathcal{M}\) \EndIf
  \If{\(P < D\)} \State \(W_{\min}\gets W+1\) \Else \State \(W_{\max}\gets W-1\) \EndIf
\EndWhile
\State \Return \(\mathcal{M}^\star\) \Comment{Best-effort if tolerance unmet}
\end{algorithmic}
\end{algorithm}
% Paper editing ends
\subsection{Budget‑Matched Window Selection and Merging}
As illustrated in Algorithm~\ref{alg:adaptive}, let \(L=|T|\) be region length and let the user specify a target reduction \(\rho\!\ge\!1\) (e.g., \(\rho\!=\!4\) means keeping roughly \(L/\rho\) instructions). We compute a keep budget \(B=\lfloor L/\rho \rfloor\). Around each boundary \(b\in\mathcal{B}\), we place a symmetric window with a half‑width that scales with local contrast:
\[
\Delta_b=\big|\,s_{b^+}-s_{b^-}\,\big|,\qquad
w_b = w_{\min} + \alpha\cdot \Delta_b,
\]
where \(s_{b^-}\) and \(s_{b^+}\) are robust pre/post means from small guard bands, \(w_{\min}\) prevents vanishing windows, and \(\alpha\) controls budget allocation toward sharp transitions. We then:

1) sort boundaries by \(\Delta_b\) (descending) and instantiate provisional windows \([b-w_b,\,b+w_b]\);

2) merge overlaps deterministically left‑to‑right, always preferring earlier start positions to avoid oscillation;

3) compute the union length \(U\). If \(U>B\), shrink all \(w_b\) by a common factor found by bisection so that the merged union meets \(B\) within a small tolerance; if \(U<B\), expand by the same procedure but clamp at segment edges.

This yields a unique, reproducible keep‑list that concentrates budget near the most consequential regime changes while guaranteeing the requested reduction.


\subsection{Learning‑Free Fallback}\label{subsec:beta}
When training is undesirable (e.g., new ISA, privacy constraints), we provide a contiguous, phase‑sensitive surrogate without learning. We repeat each standardized anchor \(\tilde{r}_{g(t)}\) over its retire group to obtain a stepwise series and solve a 1‑D TV denoising problem
\[
s^{\beta}=\arg\min_s \tfrac{1}{2}\sum_{t=1}^{|T|}\big(s_t-\tilde{r}_{g(t)}\big)^2+\lambda_{\mathrm{TV}}\!\sum_{t=2}^{|T|}|s_t-s_{t-1}|,
\]
which “uncompresses” anchors into a contiguous per‑instruction signal. We then run the identical \cpd\,+\,windowing pipeline. Although \(s^{\beta}\) lacks learned context, it preserves boundary locality sufficiently to deliver meaningful speedups under modest error budgets and serves as a robust fallback.

\subsection{Practical Notes}
- Features. We use lightweight, simulator‑available features (PC, opcode/µop class, simple address abstractions, small‑radius reuse/footprint summaries). No backward dependence on future instructions is introduced at inference.

- Robustness. Huber AC and TV regularization stabilize \(s_t\) under noisy anchors. Standardization and moment pinning make contrasts comparable across programs.

- Determinism. We fix random seeds for masking and training; window merging is order‑deterministic. Given a region, anchors, and configuration, the keep‑list is exactly reproducible.




\section{Evaluation on Single-Core Applications} 
\label{evaluation_sc}
We evaluate VitaBeta on reduced SimPoint traces versus full SimPoint traces.

\subsection{Simulation Methodology}
\label{subsec:expsetup}
\textbf{Workloads.} We select memory-intensive traces from SPEC CPU2006~\cite{spec2006}, SPEC CPU2017~\cite{spec2017}, GAP~\cite{beamer2017gapbenchmarksuite}, and ten server workloads collected with gem5~\cite{gem52011} in full-system mode and converted to ChampSim format~\cite{llbp_workloads}. We use reference inputs for SPEC and real/synthetic inputs for GAP.

The ten server traces consist of real-world applications: Eight traces from Java benchmark suites: BenchBase \cite{oltp_bench}, Renaissance \cite{java_renaissance}, and DaCapo \cite{java_dacapo}. Two traces capturing web-server activity: Node.js and PHP-FPM.
% \end{itemize}

\textbf{Environment.} Simulations use a modified ChampSim\cite{ChampSim}, coupled with Ramulator 2.0\cite{luo2023ramulator20modernmodular} for DRAM modeling. We warm up for 10M instructions and collect stats for the next 500M.

\textbf{System configuration.} Table~\ref{tab:baseline} lists a modern OoO baseline. Aggregate anchor signals including IPC (training data) are collected in a fast pass without prefetchers (about 29.27\% faster than prefetcher-enabled simulation), then used to train/apply the PTS model.

\begin{table}[!htbp]
\centering 
\caption{Simulation parameters of the baseline system.}
\begin{tabular}{|l|l|}
\hline
\textbf{Core} & \begin{tabular}[c]{@{}l@{}}
Out-of-order, 4\,GHz \\
8-fetch/decode, 6-dispatch/retire, 512-entry ROB\\
192-entry LQ, 114-entry SQ, 205-entry scheduler
\end{tabular} \\
\hline
\textbf{Caches} & \begin{tabular}[c]{@{}l@{}}
L1I: 32 KB, 64 sets, 8-way, 64B lines, 3 cycles \\
L1D: 48 KB, 64 sets, 12-way, 64B lines, 4 cycles \\
L2: 512 KB, 1024 sets, 8-way, 64B lines, 9 cycles \\
LLC: 2 MB, 2048 sets, 16-way, 64B lines, 40 cycles, LRU 
\end{tabular} \\
\hline
\textbf{BP} & Hashed perceptron predictor~\cite{hashed_perceptron} \\
\hline
\textbf{DRAM} & \begin{tabular}[c]{@{}l@{}}
DDR5-3200, Ramulator 2.0 \\
2 ch, 2 rank/ch, 8 bank groups\\
4 banks/group, 32-bit channel \\
tCAS/tRCD/tRP: 24/24/24, tRAS: 52 \\
Zen4-like mapping
\end{tabular} \\
\hline
\end{tabular}
\label{tab:baseline} 
\end{table}

\textbf{Prefetchers.} We test BERTI~\cite{navarro2022berti}, Bingo~\cite{bingo}, and SPP~\cite{spp}.

\textbf{Model evaluation.} 
We consider:
(i) \emph{pre-trained} PTS models trained on a single representative trace and applied across benchmarks, and
(ii) \emph{application-specific} models trained on the top-weight SimPoints of each application. Unless stated otherwise, results use an ImputeFormer pre-trained on a 10B-instruction \texttt{bfs-10} trace.
We retain SimPoint weights unchanged. For each SimPoint, VitaBeta outputs a reduced trace by concatenating preserved chunks; the final result is the weighted sum over SimPoints.

\subsection{Overhead Analysis}
\label{subsec:overhead}
Let $T_{\text{full}}$ be the time to simulate a full trace once, $T_{\text{prof}}$ the one-time simulation pass used to extract features, and $O$ the remaining one-time overheads (model inference or training, plus CPD+pruning). With reduction factor $r$, each pruned simulation takes $T_{\text{full}}/r$, so the per-run saving versus full simulation is $T_{\text{full}}\!\left(1-\frac{1}{r}\right)$. The break-even number of reduced runs that amortizes the one-time costs is
\begin{equation}
\label{eq:breakeven}
n_{\text{break}} \;\ge\; \frac{r\,(T_{\text{prof}} + O)}{T_{\text{full}}(r-1)}.
\end{equation}
If the profiling pass can be amortized or reused across a design sweep, set $T_{\text{prof}}\!\approx\!0$; otherwise a conservative choice is $T_{\text{prof}}\!\approx\!T_{\text{full}}$. In our setup, typical $T_{\text{full}}$ ranges from $\sim$2\,h (603.bwaves\_s-2609B) to $\sim$6\,h (605.mcf\_s-1644B). 

The one-time overhead beyond profiling is $O{=}0.5$\,h for inference with a pre-trained model or $O{\approx}36$\,h for training from scratch, plus $53$\,min for CPD+pruning (measured on NVIDIA RTX~4090 for learning and Intel Xeon Gold~6338 for simulation/pruning), yielding $O{=}1.38$\,h (pre-trained) or $O{=}36.88$\,h (custom training). As a concrete example, with $r{=}8$ and $T_{\text{full}}{=}5$\,h (bc-12), taking $T_{\text{prof}}{=}T_{\text{full}}$ gives
$n_{\text{break}} \!\ge\! \tfrac{8(5+1.38)}{5\cdot7}\!\approx\!1.46$ (two runs) for the pre-trained case, and
$n_{\text{break}} \!\ge\! \tfrac{8(5+36.88)}{5\cdot7}\!\approx\!9.57$ (about ten runs) when training from scratch. Hence, a pre-trained model yields net benefit after only a few reduced simulations, whereas custom training pays off when many runs are planned.


\subsection{Metrics}
We report the following performance metrics:
\begin{itemize}[nosep, leftmargin=*]
    \item \textbf{IPC Error ($E_{\text{IPC}}$)}: The relative error in cumulative IPC between the reduced and full-length trace simulations.
    \item \textbf{Cache Miss Rate Error ($E_{\text{Cache\_miss}}$)}: The relative error in cache miss rates, averaged across all cache levels.
    \item \textbf{Cache Access Latency Error ($E_{\text{Cache\_latency}}$)}: The relative error in average cache access {latency (lat.)}.
    \item \textbf{TLB Miss Rate Error ($E_{\text{TLB\_miss}}$)}: The relative error in miss rates for Translation Lookaside Buffer.
    \item \textbf{TLB Latency Error ($E_{\text{TLB\_latency}}$):} The relative error in averaged TLB access {latency (lat.)}.
    \item \textbf{Simulation Speed-up}: The factor by which the simulation time is reduced compared to the original SimPoint trace.
\end{itemize}
For prefetchers we also report the error of relative IPC improvement, and errors of prefetch accuracy and coverage.
\begin{itemize}[nosep, leftmargin=*]
    \item \textbf{IPC Improvement}: The proportional improvement in IPC when the prefetcher is enabled, relative to a no-prefetcher baseline:
    \[
    \text{IPC Improvement} = \frac{\text{IPC}_{\text{with prefetcher}} - \text{IPC}_{\text{no prefetcher}}}{\text{IPC}_{\text{no prefetcher}}}.
    \]
    \item \textbf{Prefetch Accuracy}: The ratio of effective (USEFUL) prefetches to the total number of issued prefetches:
    \[
    \text{Accuracy} = \frac{\text{USEFUL}}{\text{USEFUL} + \text{USELESS}}.
    \]
    \item \textbf{Prefetch Coverage}: The fraction of cache-miss events that are mitigated by effective prefetching, defined as :
    \[
    \text{Coverage} = \frac{\text{USEFUL}}{\text{USEFUL} + \text{LOAD\_MISS} + \text{RFO\_MISS}}.
    \]
\end{itemize}
\begin{figure*}[!htbp] 
    \centering
    \subfloat[Cumulative IPC error (\%).]{
        \includegraphics[width=0.325\textwidth]{individual_boxplot_RDR_IPC_mean_error.pdf}
    }
    \subfloat[Cache miss error (\%).]{
        \includegraphics[width=0.325\textwidth]{individual_boxplot_RDR_cache_miss_error.pdf}
    }
    \subfloat[Cache latency error (\%).]{
        \includegraphics[width=0.325\textwidth]{individual_boxplot_RDR_cache_latency_error.pdf}
    }
    \caption{Error distributions for $2\times$, $4\times$, and $10\times$ reductions on SPEC2006/2017, GAP, and server workloads using a pre-trained PTS model. Average speedups: $1.9\times$, $3.9\times$, $9.2\times$. \textit{\small Note: Unless stated otherwise, results in the section use an ImputeFormer pre-trained on a 10B-instruction \texttt{bfs-10} trace.}}
    \label{fig:distribution_perf}
\end{figure*}


\subsection{Results}
\subsubsection*{General Performance}
Figure~\ref{fig:distribution_perf} shows that about 75\% of traces have IPC error below 5\% at $2\times$ reduction; this increases modestly at $10\times$ while speedups scale sublinearly with the reduction factor due to fixed costs. Outliers are bandwidth-bound kernels (e.g., \texttt{GemsFDTD}, \texttt{bwaves}, \texttt{roms}, \texttt{mcf}) where small misalignment in preserved segments can amplify cache errors; even then, IPC errors generally remain below 17.5\%.

Overall, the boxplots confirm that VitaBeta maintains traces of their architectural fidelity across diverse application domains, with only a handful of predictable outliers, and that performance gains scale almost proportionally with trace-length reduction.
\begin{figure}[!htbp]
    \centering
    \setlength{\belowcaptionskip}{-10pt}
    \captionsetup{skip=3pt}
    \captionsetup[subfigure]{font=footnotesize, skip=1pt}
    \includegraphics[width=0.99\linewidth]{images/overall_performance/error_metrics_speedup_benchmark_comparison.pdf}
    \caption{Benchmark-level performance with a pre-trained PTS model at $2\times$ reduction. Error bars: standard deviation.}
    \label{fig:benchmarks}
\end{figure}

\subsubsection*{Across Benchmark Suites}
Figure~\ref{fig:benchmarks} shows SPEC2017 attains the lowest cache errors; GAP exhibits higher IPC and TLB-related errors due to irregular memory behavior and large footprints, yet still benefits from reduction.

\begin{figure*}[!htbp]
    \centering
    \captionsetup{skip=3pt}
    \captionsetup[subfigure]{font=footnotesize, skip=1pt}
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/prefetch/rel_abs_difference_vs_trace_reduction_rate.pdf}
        \caption{Relative IPC improvement error (\%).}
    \end{subfigure}
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/prefetch/rel_abs_difference_on_accuracy_vs_trace_reduction_rate.pdf}
        \caption{Prefetch accuracy error (\%).}
    \end{subfigure}
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/prefetch/rel_abs_difference_on_coverage_vs_trace_reduction_rate.pdf}
        \caption{Prefetch coverage error (\%).}
    \end{subfigure} 
    \caption{Relative prefetcher accuracy on pruned traces (pre-trained PTS model), averaged over SPEC2006/2017, GAP, and server workloads. Mean IPC improvements for full-traces: BERTI 20.28\%, Bingo 27.80\%, SPP 34.50\%.}
    \label{fig:prefetch_perf}
\end{figure*}

\begin{figure*}[!htbp] 
    \centering
    \captionsetup{skip=3pt}
    \captionsetup[subfigure]{font=footnotesize, skip=1pt}
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/prefetch/rel_abs_difference_vs_benchmark_2X_rdr.pdf}
        \caption{IPC improvement error at $2\times$.}
    \end{subfigure}
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/prefetch/rel_abs_difference_vs_benchmark_4X_rdr.pdf}
        \caption{IPC improvement error at $4\times$.}
    \end{subfigure}
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/prefetch/rel_abs_difference_vs_benchmark_10X_rdr.pdf}
        \caption{IPC improvement error at $10\times$.}
    \end{subfigure} 
    \caption{Prefetcher IPC-improvement errors across benchmark suites (pre-trained PTS model).}
    \label{fig:prefetch_benchmark}
\end{figure*}

\subsubsection*{Relative Prefetcher Performance}
Figure~\ref{fig:prefetch_perf} shows that the ordering among BERTI, Bingo, and SPP is preserved up to $4\times$ reduction and remains informative at $10\times$ for workloads with larger baseline gains (e.g., GAP). 
% Prefetch accuracy and coverage errors stay below $\sim$1–1.5\%.

 At higher reduction rates from (\(8\times\) to \(10\times\)), however, the error can exceed half the difference between the IPC improvements of any two prefetchers and the results may not be reliable. This effect is particularly pronounced for benchmarks with low baseline IPC improvements. For example, Figure~\ref{fig:prefetch_benchmark} shows that server traces, with a baseline improvement of only 7.64$\%$, exhibit relative errors of 1.41\%, 3.17\%, and 3.95\% under \(2\times\), \(4\times\), and \(10\times\) reductions, respectively. In contrast, benchmarks with higher baseline IPC improvements (e.g., GAP with 63.32\%) maintain a robust relative accuracy of prefetchers even at higher reduction rates.
 
Additionally, prefetch accuracy and coverage errors stay below $\sim$1–1.5\% for trace reductions between \(2\times\) and \(10\times\). These metrics are retained very similar   between both sets of runs and help prefetcher designer make the right analysis and conclusions
\begin{figure*}[!htbp]
    \centering
    \captionsetup{skip=3pt}
    \captionsetup[subfigure]{font=footnotesize, skip=1pt}
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{server_2x_performance_comparison.pdf}
        \caption{$2\times$ reduction.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{server_4x_performance_comparison.pdf}
        \caption{$4\times$ reduction.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{server_10x_performance_comparison.pdf}
        \caption{$10\times$ reduction.}
    \end{subfigure}
 \caption{Performance on server workloads with various prefetchers: metric errors vs. reduction (pre-trained PTS model).}
    \label{fig:abs_prefetch_perf}
\end{figure*}

\subsubsection*{Server Workloads}
Figure~\ref{fig:abs_prefetch_perf}  summarizes the performance of VitaBeta with 3 different prefetchers  on 10 server workloads. It shows most metrics remain within $\le$10\% error up to $10\times$ reduction, with speedups saturating near $9.4\times$ due to fixed costs. TLB miss errors are higher than SPEC/GAP at aggressive reductions, reflecting large, locality-optimized heaps and GC behavior that make TLB dynamics sensitive to trace pruning.

\subsubsection*{Branch Prediction Accuracy}
Because VitaBeta preserves sizable chunks around change points, branch distributions remain close to the originals. At $2\times$ reduction with a pre-trained model, BP accuracy errors remain small (e.g., 0.126\% SPEC2006, 0.117\% SPEC2017, 0.489\% GAP) despite significant instruction pruning in GAP.

\begin{figure*}[!htbp]  
    \centering
    \captionsetup{skip=3pt}
    \captionsetup[subfigure]{font=footnotesize, skip=1pt}
    \includegraphics[width=.99\textwidth]{publication_subplots_hatched_bars.pdf}
    \caption{Different Backbone Models for generating PTS: Beta heuristics, non-Transformers, and Transformer variants at $4\times$ reduction (no prefetchers enabled). Error bars: standard deviation.}
    \label{fig:model_perf}
\end{figure*}




 
\subsection{Sensitivity Analysis}
\subsubsection*{Model Choices}
Figure~\ref{fig:model_perf} compares Various PTS backbones. Transformer variants (SAITS/ImputeFormer) outperform non-Transformers (TEFN~\cite{TEFN}, ModernTCN~\cite{moderntcn}) and the heuristic Beta Metric, especially at higher reductions. Application-specific training offers up to $\sim$10\% additional error reduction over a strong pre-trained model; heavier models (TimesNet, TimeMixer) do not consistently outperform compact Transformers given similar training budgets.

\subsubsection*{Impact of Training Data}
Table~\ref{tab:sensitivity_training_onecol} indicates that pre-training on different representative traces yields similar aggregate accuracy; \texttt{gcc-13B} pre-training slightly improves means but increases variance due to its chaotic phase structure~\cite{Shen+:ASPLOS04}. % CITATION NEEDED


\begin{table}[htbp!]
  \caption{Different Pre-Training Traces (SPEC2017/2006/GAP), $2\times$ reduction. Prefetcher: BERTI. Values are geometric means in \%. Lower is better except Speedup.}
  \label{tab:sensitivity_training_onecol}
  \centering
  \setlength{\tabcolsep}{2pt}
  \begin{adjustbox}{max width=1.0\columnwidth}
  \begin{tabular}{l|rrrrrr}
  \toprule
  Training data & ${E}_{\text{IPC}}$  & $E_{\text{cache\_miss}}$  &$E_{\text{cache\_latency}}$  & $E_{\text{TLB\_miss}}$    & $E_{\text{TLB\_latency}}$   & Speedup \\
  \midrule
  astar-313B & \textbf{3.224\%} & 2.625\% & \textbf{1.783\%} & 3.655\% & 4.213\% & $1.971\times$ \\
  bfs-10     & 3.458\% & \textbf{2.373\%} & 1.926\% & 3.283\% & 4.498\% & $1.952\times$ \\
  gcc-13B    & 3.229\% & 2.456\% & 2.094\% & \textbf{2.787\%} & \textbf{4.190\%} & \textbf{$1.989\times$} \\
  \bottomrule
  \end{tabular}
  \end{adjustbox}
  \vspace{0.25ex}
  \\
  \footnotesize Note: Same ImputeFormer hyperparameters; models are pre-trained on different traces and evaluated across the suites.
\end{table}


\subsubsection*{CPD Cost Functions}
We conduct experiments comparing the {Auto-Regressive ($AR$)} cost function with the {Least Squared Deviation ($L_2$)} cost function. We assess their effectiveness on \textit{TimeMixer} and \textit{TimesNet}, since these two models tend to yield very high variance among all error metrics compared to other Transformer-based models. The $L_2$ cost function is defined as: $$c_{\text{$L_2$}}(y_{t_a:t_b}) = \sum_{t = t_a}^{t_b} \left( y_t - \bar{y}_{t_a:t_b} \right)^2,$$
where $\bar{y}_{t_a:t_b}$ is the mean of the segment $[t_a, t_b]$. 
While $AR$ is suitable for time series where current values are influenced by past values, the $L_2$ cost function is effective for detecting shifts in the mean level of the signal\cite{Lavielle2005}.   

Table~\ref{tab:sensitivity_cpd_onecol} shows TimeMixer prefers AR cost (temporal dependence), while TimesNet prefers $L_2$ (mean shifts). Selecting a CPD cost aligned with the backbone’s inductive bias improves stability.
\begin{table}[htbp!]
  \caption{CPD cost functions with different backbones (SPEC2017/2006/GAP), $2\times$ reduction. Prefetcher: BERTI. Values are geometric means in \%. Lower is better except Speedup.}
  \label{tab:sensitivity_cpd_onecol}
  \centering
  \setlength{\tabcolsep}{2pt}
  \begin{adjustbox}{max width=1.0\columnwidth}
  \begin{tabular}{l|rrrrrr}
  \toprule
  Approach &  $E_{\text{IPC}}$  & $E_{\text{cache\_miss}}$  &$E_{\text{cache\_latency}}$  & $E_{\text{TLB\_miss}}$    & $E_{\text{TLB\_latency}}$   & Speedup\\
  \midrule
  \footnotesize TimeMixer + AR-CPD    & \textbf{2.175\%} & \textbf{1.249\%} & \textbf{1.400\%} & \textbf{2.702\%} & \textbf{3.207\%} & $1.959\times$ \\
  \footnotesize TimeMixer + $L_2$-CPD  & 2.870\% & 1.392\% & 1.419\% & 3.313\% & 4.234\% & \textbf{$2.035\times$} \\
  \midrule
  \footnotesize TimesNet + AR-CPD     & 3.514\% & 1.924\% & 2.675\% & 3.217\% & 4.223\% & $1.995\times$ \\
   \footnotesize TimesNet + $L_2$-CPD     & \textbf{3.027\%} & \textbf{1.789\%} & \textbf{2.356\%} & \textbf{3.495\%} & \textbf{3.720\%} & $1.987\times$ \\
  \bottomrule
  \end{tabular}
  \end{adjustbox}
  \vspace{0.25ex}
  \\
  \footnotesize Note: Each Backbone model share the same hyperparameters; only the CPD cost differs.
\end{table}

\section{Evaluation on Multi-Core Applications} 
\label{evaluation_mc}
\textbf{Experimental setup.} We follow LoopPoint in gem5 full-system~\cite{LoopPointTutorialHPCA23} on seven NAS Parallel Benchmarks~\cite{npb_benchmark} (Class A~\cite{npb_input_size}, 4 OpenMP threads) with a Skylake-like quad-core (Table~\ref{tab:detailed_board}) baseline configuration.

\begin{table}[!htbp]
\centering
\caption{Configuration of detailed gem5 FS simulation.}
\begin{tabular}{|l|l|}
\hline
\textbf{CPU Model} & Out-of-order, 4\,GHz, SkyLakeCPU (4 cores) \\ 
\hline
\textbf{Caches} & \begin{tabular}[c]{@{}l@{}}
L1I/L1D: 64 KB, 8-way;\; L2: 2 MB, 64-way \\
Coherence: MESI two-level
\end{tabular} \\
\hline
\textbf{System} & Ubuntu 24.04 (4 CPUs, built with QEMU~\cite{qemu}) \\
\hline
\textbf{DRAM} & DDR4\_2400\_16x4, 3GB \\
\hline
\end{tabular}
\label{tab:detailed_board}
\end{table}
\vspace{-0.5cm}
\subsection{LoopPoint Workflow}
\begin{enumerate}[nosep, leftmargin=*]
  \item \textbf{Boot Checkpointing.}  
        We fast-forward a Ubuntu 24.04 image to the shell prompt with a
        \textit{X86KvmCPU} and save an \emph{after-boot} snapshot.
        This removes the OS boot path from all subsequent experiments.
  \item \textbf{Process-map Extraction.}  
        Restoring the boot image we launch the
        NPB binary and dump
        \emph{/proc/\$PID/maps}.  
        We filter the map to get (i) the application
        text segment---used later to validate marker PCs—and
        (ii) ``unsafe'' ranges (OpenMP, {pthread} etc.) that must
        be \emph{excluded} from BBV collection. 
  \item \textbf{LoopPoint analysis.}  
         We enable a \emph{LooppointAnalysis} probe that listens       inside the application’s text range; library addresses found in
        the previous step are masked out.  
        Region length  is fixed to 400M instructions.  
        We record the BBV, global instruction count and loop
        counters and then reset all statistics. 
        A typical NPB-A
        run produces $50$–$90$ regions, which are later clustered using k-means for representative  selection.         For every representative region ID (RID) we derive three
        markers (warm-up, start, end).
 
  \item \textbf{Checkpoint construction.}  
        Starting from the boot snapshot,
        we enable a
        \textit{PcCountTracker} that listens at
        \textit{WORKBEGIN}, and dumps a checkpoint whenever a warm-up or
        start marker fires.  
        Regions whose warm-up coincides with
        \textit{WORKBEGIN} are captured automatically, ensuring \emph{one
        micro-checkpoint (LoopPoint) per RID} and zero redundant state.
  \item \textbf{Detailed replay.}  
        We restores each
        LoopPoint on the detailed core
        (Tab.~\ref{tab:detailed_board}).  
        Per-region stats are scaled by the cluster weight and summed;
        the grand total is compared against an unsampled detailed run.
\end{enumerate}

\subsection{Using VitaBeta  for {LoopPoint Refinement}}
\begin{enumerate}[nosep, leftmargin=*]
\item \textbf{Generate elastic traces.}  
For each application profiled by LoopPoint, we load information from the same RID and use a modified \textit{TraceCPU} to  emit an \textit{interleaved trace} similar to Table~\ref{tab:example} from gem5 elastic traces\cite{elastic_trace_gem5} (memory data trace and instruction fetch trace).
\item \textbf{Offline pruning to generate new checkpoints.}  
    We then run VitaBeta with a target $4\times$ reduction to retains only the
      instruction spans around its detected change points. This results in a compact \emph{keep-list}:
      \(\langle\text{PC},\,\Delta\text{inst}\rangle\) pairs that delimit the surviving slices. Finally, we re-checkpoint in the same way as LoopPoint with the generated \textit{PcCountTracker}. Detailed replay on these checkpoints uses the same core configuration (Table~\ref{tab:detailed_board}).
\end{enumerate} 


\begin{figure*}[!htbp] 
    \centering
    \includegraphics[width=1.00\textwidth]{lp2.pdf}
    \caption{Per-benchmark breakdown for LoopPoint+VitaBeta (pre-trained PTS).}
    \label{fig:lp_vb_breakdown} 
\end{figure*}

\begin{figure}[!htbp] 
    \centering
    \includegraphics[width=.99\columnwidth]{lp1.pdf}
    \caption{LoopPoint vs.\ LoopPoint+VitaBeta (against unsampled detailed ground truth).}
    \label{fig:lp_vb_comparison} 
\end{figure}
% \vspace{-0.5cm}

\subsection{Results}
We evaluate three configurations:
\begin{itemize}[nosep, leftmargin=*]
    \item \textbf{Ground-truth (GT): }  full, unsampled detailed run.
    \item \textbf{LoopPoint (LP): }  vanilla LoopPoint, average 30 regions.
    \item \textbf{LP+VB: } VitaBeta-refined LoopPoints ($4\times$ reduction).
\end{itemize}
\smallskip\noindent
We sum per-region statistics weighted by region
multiplicity and report the GeoMean error of
\textsc{LP}/\textsc{LP+VB} versus \textsc{GT}.  


Figure~\ref{fig:lp_vb_comparison} shows that \textsc{LP+VB} multiplies
LoopPoint’s original $4.3\times$ speed-up to {23.9$\times$}—a $5.6\times$ additional acceleration,while IPC error rises modestly from $3.1\%$ to {9.6\%}.  Cache and DRAM latency errors remain below $10.5\%$ and $17.0\%$,
respectively.  Although VitaBeta’s pruning is uniformly aggressive, accuracy deteriorates sub-linearly corresponding to the gain in speed-up. Figure~\ref{fig:lp_vb_breakdown} indicates compute-bound workloads
(\textit{CG}, \textit{EP}) gain the most ($42$–$285\times$ speed-up),
whereas memory-intensive ones with irregular spatial locality (\textit{MG}, \textit{LU}) incur 
highest DRAM-latency error.  These high errors are caused by interleaving the multi-threading traces that coincides with page-table walks and conflict-miss bursts. Nevertheless, even for them, the IPC error stays below 20\%, and the simulator still runs an order of magnitude faster than  LoopPoint baseline. 
These results validate VitaBeta as an \emph{orthogonal}
complement to region-level sampling in multi-core full-system studies.  

% \textbf{Discussion.}
Multi-threaded traces introduce cross-core interference and barrier-aligned patterns. Two practical refinements further reduce error: (i) \emph{co-run PTS}: augment features with shared-LLC MPKI and per-core QPS to align cross-core phases; (ii) \emph{sync-guarded pruning}: inflate preservation windows around barrier and lock/unlock PCs. We applied conservative sync guards in our implementation; richer co-run PTS is left for future work.

\section{Limitations and Threats to Validity}\label{sec:limitations}
\textbf{Scope of the surrogate.} \pts is trained to be aggregate‑consistent with retire‑group throughput. It is designed to preserve metrics that correlate with throughput over short neighborhoods (e.g., IPC, cache‑miss/latency averages). Metrics dominated by rare, long‑range tail effects may require wider windows or anchors beyond IPC; otherwise, aggressive pruning can under‑represent such traces.

\textbf{Anchor quality and profiling bias.} Anchors inherit the configuration from the initial simulation pass (e.g., prefetcher on/off, warmup policy, ROB grouping). If profiling uses a configuration that materially differs from the evaluation setup, \pts can encode that bias. We mitigate this by standardizing anchors, using robust losses, and re‑profiling when configurations change.

\textbf{Aggregate identifiability and stability.} Mean‑matching alone is under‑determined. Our use of standardized anchors, TV regularization, and moment pinning yields a surrogate that is stable in practice, but extremely flat anchors (near‑constant IPC) can reduce contrast and make CPD less decisive. In such cases, penalties should favor fewer segments or the budget should be concentrated on the few boundaries with measurable contrast.

\textbf{Sensitivity to CPD and windowing hyperparameters.} Over‑segmentation increases fragmentation and warmup overhead; under‑segmentation can miss important transitions. We use an AR cost and a BIC‑style penalty that worked across suites, but poorly chosen penalties or window scales can degrade accuracy. Our budget‑matching uses global shrink/expand with deterministic merging to bound this risk; nevertheless, we recommend validating defaults on a small calibration set before large studies.

\textbf{Warmup and fixed costs.} End‑to‑end speedup saturates below the nominal reduction because of fast‑forwarding and warmup at window boundaries. Very small windows can become warmup‑dominated. Our selection enforces a minimum width and merges overlaps to reduce boundary counts, but extremely high reduction targets may still be limited by fixed costs.

\textbf{Multi‑core interference and synchronization.} In multi‑threaded workloads, barriers and lock‑intensive regions are sensitive to pruning because cross‑core interference can shift phase boundaries. We guard known synchronization PCs with inflated windows and, when available, include shared‑LLC/load‑queue summaries as features. More sophisticated co‑run features are promising but left for future work.

\textbf{Generalization across microarchitectures.} Pre‑trained models generalize across evaluated workload suites and several prefetchers, but transfer across substantially different cores (e.g., instruction set architecture (ISA), pipeline width, cache topology, memory hierarchy) is not guaranteed. A light re‑profiling pass and short fine‑tuning typically suffice.

\section{Conclusion} \label{summary}
We presented \name, a within‑region trace‑reduction framework that learns a contiguous per‑instruction \pts anchored by retire‑group throughput and uses principled \cpd\ with budgeted windowing to preserve only compact, phase‑defining neighborhoods. This aggregate‑consistent surrogate avoids ill‑posed instruction‑level “IPC” targets while remaining faithful to the measurable statistics that modern OoO cores expose, and composes cleanly with SimPoint and LoopPoint without altering their region selections or weights. A learning‑free fallback (\S\ref{subsec:beta}) enables deployment even when training is infeasible.

Comprehensive evaluation on SPEC CPU2006/2017, GAP, and ten server workloads shows that \name achieves up to $10{\times}$ trace reduction with mean errors of 5.47\% (IPC), 4.01\% (cache miss), and 2.97\% (cache latency), and delivers a $9.23{\times}$ end‑to‑end speedup with a pre‑trained Transformer. Importantly, \name preserves comparative conclusions: across BERTI, Bingo, and SPP, the absolute error in \emph{relative} IPC improvement remains low (4.05\% at $4{\times}$, 5.79\% at $10{\times}$), maintaining prefetcher ranking. On multi‑core full‑system runs, \name multiplies LoopPoint’s speedup by $5.6{\times}$ with moderate accuracy loss (IPC/cache‑miss/cache‑latency errors of 9.6\%/16.3\%/8.3\%), validating orthogonality to region‑level sampling.

By casting fine‑grained pruning as learning from aggregates and coupling it with exact segmentation, \name turns a single profiling pass into a robust driver for high‑fidelity acceleration. Looking ahead, we see three promising directions: (i) cross‑microarchitecture transfer via light re‑profiling and fine‑tuning of \pts; (ii) co‑run \pts features and synchronization‑aware guards to further stabilize multi‑core pruning; and (iii) anchors beyond IPC (e.g., memory‑system signals) to target specific studies. We believe \name provides a practical path to substantially faster, faithful architectural simulation, enabling broader design sweeps and more timely evaluation of emerging microarchitectural ideas.
% \balance
\bibliographystyle{IEEEtran}
\bibliography{refs}
\end{document}
```
